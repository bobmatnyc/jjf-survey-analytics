# CLAUDE.md - AI Agent Instructions

**Project:** JJF Survey Analytics Platform
**Last Updated:** 2025-10-09
**Version:** 1.0.0

> This file provides comprehensive instructions for Claude Code and other AI agents working on this project. All operations follow the "ONE way to do ANYTHING" principle.

---

## Quick Links

- [README.md](README.md) - Project overview and user guide
- [DEVELOPER.md](DEVELOPER.md) - Technical architecture and API docs
- [ARCHITECTURE.md](ARCHITECTURE.md) - System architecture details
- [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) - Deployment procedures
- [QUICK_REFERENCE.md](QUICK_REFERENCE.md) - Common commands

---

## Project Overview

**JJF Survey Analytics Platform** is a comprehensive survey data management and analytics platform that:
- Extracts survey data from Google Sheets
- Normalizes data into a relational database
- Provides real-time analytics dashboards
- Automatically synchronizes with data sources
- Deploys to Railway with PostgreSQL support

**Tech Stack:**
- **Backend:** Python 3.13, Flask 2.3+, SQLAlchemy 2.0+
- **Database:** SQLite (local), PostgreSQL (production)
- **Frontend:** Tailwind CSS, vanilla JavaScript
- **Deployment:** Railway with gunicorn
- **APIs:** Google Sheets API v4

---

## ğŸ”´ CRITICAL - Essential Commands

### Start Local Development Server
```bash
python app.py
```
- **URL:** http://localhost:8080
- **Auth:** Disabled by default (set `REQUIRE_AUTH=true` to enable)
- **Auto-reload:** Enabled in development mode

### Extract Data from Google Sheets
```bash
python improved_extractor.py
```
- Creates/updates `surveyor_data_improved.db`
- Extracts from 6 predefined JJF Technology Assessment spreadsheets

### Normalize Survey Data
```bash
python survey_normalizer.py --auto
```
- Processes raw data into `survey_normalized.db`
- Creates relational structure with proper typing

### Run All Tests
```bash
make test
```
- Executes pytest test suite
- Coverage reports in `htmlcov/`

---

## ğŸŸ¡ IMPORTANT - Common Operations

### Development Setup
```bash
# Create virtual environment
python -m venv venv

# Activate (Mac/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Database Operations
```bash
# Initialize database
python main.py init-db

# Check extraction status
python main.py status

# Extract with verbose logging
python main.py --verbose extract --use-default-urls
```

### Health Checks
```bash
# Run all health checks
python healthcheck.py

# API validation only
python healthcheck.py --api-only

# Dependencies check only
python healthcheck.py --deps-only
```

### Code Quality
```bash
# Run linting
make lint

# Format code
make format

# Run tests with coverage
make test-cov
```

---

## ğŸŸ¢ STANDARD - Additional Workflows

### Clean Up Environment
```bash
make clean
```
- Removes `__pycache__`, `.pyc` files
- Cleans build artifacts and coverage reports

### View Application Logs
```bash
# Local development
tail -f app.log

# Railway deployment
railway logs
```

### Manual Data Sync
Visit http://localhost:8080/sync and click "Force Sync Now"

---

## âšª OPTIONAL - Advanced Operations

### Railway Deployment (Use with Caution)
```bash
# The definitive deployment is managed by Railway's GitHub integration
# Manual deployments are NOT recommended

# If you must deploy manually:
railway up  # Only if railway CLI is configured
```

**PREFERRED METHOD:** Push to GitHub, Railway auto-deploys from master branch

### Custom CLI Commands
```bash
# Using the surveyor CLI tool
surveyor extract --use-default-urls
surveyor status
```

---

## ğŸ—ï¸ Project Architecture

### Directory Structure
```
jjf-survey-analytics/
â”œâ”€â”€ app.py                      # ğŸ”´ Main Flask application
â”œâ”€â”€ railway_app.py              # Railway-specific deployment
â”œâ”€â”€ survey_analytics.py         # Analytics engine
â”œâ”€â”€ survey_normalizer.py        # ğŸ”´ Data normalization
â”œâ”€â”€ improved_extractor.py       # ğŸ”´ Google Sheets extractor
â”œâ”€â”€ auto_sync_service.py        # Background sync service
â”œâ”€â”€ healthcheck.py              # Health monitoring
â”‚
â”œâ”€â”€ healthcheck/                # Health check modules
â”‚   â”œâ”€â”€ api_validators.py
â”‚   â”œâ”€â”€ dependency_checker.py
â”‚   â”œâ”€â”€ e2e_tests.py
â”‚   â””â”€â”€ monitoring.py
â”‚
â”œâ”€â”€ templates/                  # ğŸŸ¡ Jinja2 HTML templates
â”‚   â”œâ”€â”€ base.html              # Base template with nav
â”‚   â”œâ”€â”€ dashboard.html         # Main dashboard
â”‚   â”œâ”€â”€ survey_analytics.html  # Analytics view
â”‚   â”œâ”€â”€ survey_responses.html  # Response activity
â”‚   â”œâ”€â”€ sync_dashboard.html    # Auto-sync management
â”‚   â””â”€â”€ health_dashboard.html  # Health monitoring
â”‚
â”œâ”€â”€ src/surveyor/              # ğŸŸ¢ Core library (optional)
â”‚   â”œâ”€â”€ cli/                   # CLI commands
â”‚   â”œâ”€â”€ config/                # Configuration
â”‚   â”œâ”€â”€ models/                # Data models
â”‚   â”œâ”€â”€ repositories/          # Data access
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â””â”€â”€ utils/                 # Utilities
â”‚
â”œâ”€â”€ hybrid_surveyor/           # âšª Advanced CLI tool (separate package)
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ PROGRESS.md
â”‚   â””â”€â”€ work-logs/
â”‚
â”œâ”€â”€ surveyor_data_improved.db  # ğŸ”´ Raw spreadsheet data
â”œâ”€â”€ survey_normalized.db       # ğŸ”´ Normalized survey data
â”‚
â”œâ”€â”€ requirements.txt           # ğŸ”´ Python dependencies
â”œâ”€â”€ pyproject.toml            # Project configuration
â”œâ”€â”€ Makefile                  # ğŸŸ¡ Development commands
â”œâ”€â”€ Procfile                  # ğŸ”´ Railway startup
â””â”€â”€ railway.toml              # Railway configuration
```

### Key Files Priority
- ğŸ”´ **CRITICAL:** Required for core functionality
- ğŸŸ¡ **IMPORTANT:** Needed for development workflow
- ğŸŸ¢ **STANDARD:** Optional but recommended
- âšª **OPTIONAL:** Advanced features

---

## ğŸ—„ï¸ Database Schema

### Raw Data Database (`surveyor_data_improved.db`)
```
spreadsheets
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ spreadsheet_id
â”œâ”€â”€ title
â”œâ”€â”€ type (Survey/Assessment/Inventory)
â””â”€â”€ last_synced

raw_data
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ spreadsheet_id (FOREIGN KEY)
â”œâ”€â”€ sheet_name
â”œâ”€â”€ data (JSON)
â””â”€â”€ extracted_at

extraction_jobs
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ status
â”œâ”€â”€ started_at
â””â”€â”€ completed_at
```

### Normalized Survey Database (`survey_normalized.db`)
```
surveys
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ name
â”œâ”€â”€ type
â””â”€â”€ created_at

survey_questions
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ survey_id (FOREIGN KEY)
â”œâ”€â”€ question_text
â”œâ”€â”€ question_type
â””â”€â”€ order_index

survey_responses
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ survey_id (FOREIGN KEY)
â”œâ”€â”€ respondent_id (FOREIGN KEY)
â”œâ”€â”€ submitted_at
â””â”€â”€ raw_data (JSON)

survey_answers
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ response_id (FOREIGN KEY)
â”œâ”€â”€ question_id (FOREIGN KEY)
â”œâ”€â”€ answer_value
â”œâ”€â”€ answer_type
â””â”€â”€ parsed_value

respondents
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ email
â”œâ”€â”€ name
â””â”€â”€ organization

sync_tracking
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ last_sync
â”œâ”€â”€ records_synced
â””â”€â”€ status

normalization_jobs
â”œâ”€â”€ id (PRIMARY KEY)
â”œâ”€â”€ status
â”œâ”€â”€ started_at
â””â”€â”€ completed_at
```

---

## ğŸ”’ Data Architecture: Single Source of Truth

### Google Sheets as Single Source of Truth

**CRITICAL PRINCIPLE:** Google Sheets are the ONLY authoritative data source. All databases are disposable caches.

#### Architecture Rules

1. âœ… **Google Sheets â†’ Databases** (One-way data flow)
2. âŒ **Databases â†’ Google Sheets** (NO reverse flow)
3. âœ… **Databases can be deleted safely** (Data lives in Google Sheets)
4. âœ… **Databases regenerate automatically** (From Google Sheets)

#### Data Flow Architecture

```
Google Sheets (SINGLE SOURCE OF TRUTH)
        â†“ READ-ONLY
improved_extractor.py (Extract)
        â†“
Raw Database (DISPOSABLE CACHE)
â”œâ”€ SQLite: surveyor_data_improved.db (local)
â””â”€ PostgreSQL: Raw tables (production)
        â†“
survey_normalizer.py (Normalize)
        â†“
Normalized Database (DISPOSABLE CACHE)
â”œâ”€ SQLite: survey_normalized.db (local)
â””â”€ PostgreSQL: Normalized tables (production)
        â†“
Flask Application (app.py)
        â†“
User Interface (READ-ONLY)
```

#### Database Regeneration

**Local Development (SQLite):**
```bash
# Safe to delete - data lives in Google Sheets
rm surveyor_data_improved.db survey_normalized.db

# Regenerate from Google Sheets (takes ~60 seconds)
python improved_extractor.py
python survey_normalizer.py --auto
```

**Production (PostgreSQL on Railway):**
- **Automatic:** Railway deployment regenerates PostgreSQL from Google Sheets on startup
- **Manual:** Restart Railway service to force full regeneration
- **Emergency:** Delete PostgreSQL database - will regenerate on next deployment

#### Database Environment Detection

The system automatically detects the environment:

- **`DATABASE_URL` NOT set** â†’ SQLite mode (local development)
  - Creates `.db` files in project directory
  - Suitable for development and testing

- **`DATABASE_URL` IS set** â†’ PostgreSQL mode (production)
  - Connects to PostgreSQL via DATABASE_URL
  - Railway automatically sets this variable
  - No `.db` files created

#### SOT Compliance Guarantees

âœ… **Zero write operations to Google Sheets** - All code is read-only
âœ… **Databases are gitignored** - Not version controlled
âœ… **Full refresh on sync** - Not incremental updates
âœ… **Automatic regeneration** - Railway startup extracts from Sheets
âœ… **Manual regeneration** - Run extractor anytime

#### What This Means for Development

**You CAN safely:**
- Delete any database file (`.db` or PostgreSQL)
- Modify database schema without migrations
- Experiment with database structure locally
- Reset to clean state anytime

**You CANNOT:**
- Modify survey data without updating Google Sheets
- Create "admin" features that edit database directly
- Trust database as authoritative source
- Rely on database data persisting across deployments

#### Troubleshooting Data Issues

**Problem:** Production data looks wrong
**Solution:** Restart Railway service to regenerate from Google Sheets

**Problem:** Local database is corrupted
**Solution:** `rm *.db && python improved_extractor.py && python survey_normalizer.py --auto`

**Problem:** Changes in Google Sheets not showing
**Solution:** Wait for auto-sync (5 minutes) or force sync via `/sync` dashboard

---

## ğŸŒ API Endpoints

### Web Routes (User Interface)
```
GET  /                        # Main dashboard
GET  /login                   # Authentication page
GET  /logout                  # Logout
GET  /spreadsheets            # Spreadsheets listing
GET  /spreadsheet/<id>        # Individual spreadsheet view
GET  /jobs                    # Extraction jobs history
GET  /surveys                 # Survey analytics dashboard
GET  /surveys/analytics       # Detailed question analysis
GET  /surveys/responses       # Response activity monitor
GET  /sync                    # Auto-sync management dashboard
GET  /health/dashboard        # Health check dashboard
GET  /health/test             # Run health checks
```

### API Routes (JSON)
```
GET  /api/stats                    # Dashboard statistics
GET  /api/spreadsheet/<id>/data    # Spreadsheet data
GET  /api/sync/status              # Auto-sync service status
POST /api/sync/start               # Start auto-sync service
POST /api/sync/stop                # Stop auto-sync service
POST /api/sync/force               # Force immediate sync
GET  /api/survey/search            # Search survey responses
GET  /api/survey/<id>/export       # Export survey data (CSV)
GET  /health/status                # Health check status
POST /health/check                 # Run specific health checks
```

---

## ğŸ”§ Configuration

### Environment Variables
```bash
# Application
PORT=8080                           # Server port (Railway sets this)
SECRET_KEY=your-secret-key          # Flask secret key

# Authentication
REQUIRE_AUTH=false                  # Enable/disable auth (true in production)
APP_PASSWORD=survey2025!            # App password when auth enabled

# Database
DATABASE_URL=postgresql://...       # PostgreSQL URL (Railway provides this)

# Logging
LOG_LEVEL=INFO                      # Logging verbosity

# Auto-Sync
AUTO_SYNC_INTERVAL=300              # Sync interval in seconds (5 minutes)

# Google Sheets API
GOOGLE_API_KEY=your-key             # Optional for API key auth
```

### Local Development Configuration
Create `.env` file in project root:
```env
PORT=8080
SECRET_KEY=dev-secret-key-change-in-production
REQUIRE_AUTH=false
APP_PASSWORD=survey2025!
LOG_LEVEL=DEBUG
AUTO_SYNC_INTERVAL=300
```

---

## ğŸš€ Deployment

### ONE Way to Deploy: Railway GitHub Integration

**DO NOT use manual deployment scripts.** Railway automatically deploys from GitHub.

**Deployment Workflow:**
1. Make changes locally
2. Commit to git: `git commit -m "Description"`
3. Push to GitHub: `git push origin master`
4. Railway automatically builds and deploys
5. Monitor at Railway dashboard

**Health Check:** Railway uses `/health` endpoint (configured in `railway.toml`)

**Database:** Railway automatically provisions PostgreSQL and sets `DATABASE_URL`

**See:** [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for detailed instructions

---

## ğŸ§ª Testing

### Test Structure
```
tests/
â”œâ”€â”€ unit/              # Unit tests
â”œâ”€â”€ integration/       # Integration tests
â””â”€â”€ __init__.py
```

### Run Tests
```bash
# All tests
make test

# With coverage report
make test-cov

# Specific test file
python -m pytest tests/unit/test_basic.py -v

# Integration tests only
python -m pytest tests/integration/ -v
```

### Test Coverage Goals
- **Unit Tests:** 80%+ coverage
- **Integration Tests:** Critical paths covered
- **E2E Tests:** Main user workflows validated

---

## ğŸ“Š Data Flow

```
Google Sheets (Source)
    â†“
improved_extractor.py (Extract)
    â†“
surveyor_data_improved.db (Raw Data)
    â†“
survey_normalizer.py (Normalize)
    â†“
survey_normalized.db (Relational)
    â†“
app.py (Flask Application)
    â†“
Templates (Jinja2)
    â†“
User Browser (Dashboards)
```

---

## ğŸ” Troubleshooting

### Database Not Found
```bash
# Solution: Run extractor and normalizer
python improved_extractor.py
python survey_normalizer.py --auto
```

### Port Already in Use
```bash
# Find process using port 8080
lsof -ti:8080

# Kill process
lsof -ti:8080 | xargs kill -9

# Or change port
export PORT=8081
python app.py
```

### Authentication Issues
```bash
# Disable auth for local development
export REQUIRE_AUTH=false

# Or set password
export APP_PASSWORD=your-password
```

### Google Sheets Access Denied
- Verify sheets are publicly accessible
- Check internet connection
- Validate URLs in extractor configuration

### Auto-Sync Not Working
- Check `/sync` dashboard
- Verify service is started
- Review logs for errors
- Ensure source data has changed

### Health Checks Failing
```bash
# Run manual health check
python healthcheck.py

# Check specific components
python healthcheck.py --api-only
python healthcheck.py --deps-only
```

---

## ğŸ¯ Current Project Status

### Production Statistics (As of 2025-10-03)
- **22 survey responses** processed across 5 surveys
- **240 questions** normalized with proper typing
- **585 answers** analyzed with statistical insights
- **13 unique respondents** tracked
- **6 Google Sheets** sources (2 Surveys, 3 Assessments, 1 Inventory)

### Recent Updates (Last 30 Days)
- âœ… **PostgreSQL Schema Migration** - Full compatibility with Railway production database
- âœ… **Single Source of Truth Architecture** - Auto-regenerating PostgreSQL from Google Sheets
- âœ… **Sync Tracking Improvements** - Fixed INSERT OR REPLACE conversion for PostgreSQL
- âœ… **UI Terminology Standardization** - Unified 'submission' terminology across interface
- âœ… **Comprehensive Documentation** - Added development guides and deployment docs
- âœ… **Enhanced Makefile** - Complete command system with shortcuts
- âœ… **Security Documentation** - Added v1.0.1 security debt tracking

### Deployment Status
- âœ… **Railway Production:** Live and auto-deploying from GitHub
- âœ… **PostgreSQL:** Database provisioned and connected
- âœ… **Health Checks:** Active monitoring at `/health`
- âœ… **Authentication:** Configurable (disabled for local dev)

---

## ğŸ“ Development Guidelines

### Code Style
- **Python:** PEP 8 compliant, use Black formatter (line length 100)
- **Type Hints:** Use type hints for all function signatures
- **Docstrings:** Required for public functions and classes
- **Imports:** Organize with isort (stdlib, third-party, local)

### Git Workflow
```bash
# Create feature branch
git checkout -b feature/your-feature-name

# Make changes and commit
git add .
git commit -m "feat: Add your feature description"

# Push to GitHub
git push origin feature/your-feature-name

# Create pull request on GitHub
# After review, merge to master
# Railway auto-deploys from master
```

### Commit Message Convention
```
feat: Add new feature
fix: Fix bug
docs: Update documentation
style: Format code
refactor: Refactor code structure
test: Add tests
chore: Update dependencies
```

---

## ğŸ§  Memory System

This project uses Claude MPM (Memory and Project Management) for knowledge retention.

**Memories Location:** `.claude-mpm/memories/`

**Update Memories When:**
- Learning new project patterns
- Discovering architecture decisions
- Identifying important workflows
- Solving complex bugs

**Memory Format:**
```json
{
  "memory-update": {
    "Project Architecture": ["Key architectural insight"],
    "Implementation Guidelines": ["Important coding practice"],
    "Current Technical Context": ["Project-specific detail"]
  }
}
```

---

## âš ï¸ Important Warnings

### DO NOT
- âŒ **Manual Railway Deployments** - Use GitHub integration only
- âŒ **Commit Secrets** - Never commit `.env` files or API keys
- âŒ **Modify Production DB Directly** - Use migration scripts
- âŒ **Skip Tests** - Always run tests before pushing
- âŒ **Use Multiple Deployment Scripts** - One method: GitHub â†’ Railway

### DO
- âœ… **Use Virtual Environment** - Isolate dependencies
- âœ… **Run Health Checks** - Before and after changes
- âœ… **Update Documentation** - Keep docs synchronized
- âœ… **Test Locally First** - Verify changes before push
- âœ… **Follow Git Workflow** - Branch, commit, push, PR

---

## ğŸ“š Additional Documentation

### Primary Documentation
- [README.md](README.md) - Comprehensive project overview
- [DEVELOPER.md](DEVELOPER.md) - Technical architecture and development guide
- [ARCHITECTURE.md](ARCHITECTURE.md) - System design and architecture
- [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) - Deployment procedures
- [SOT_ARCHITECTURE.md](SOT_ARCHITECTURE.md) - Single Source of Truth architecture

### Feature Documentation
- [AUTO_SYNC_IMPLEMENTATION.md](AUTO_SYNC_IMPLEMENTATION.md) - Auto-sync service details
- [AUTHENTICATION_CONFIG.md](AUTHENTICATION_CONFIG.md) - Authentication setup
- [HEALTHCHECK_README.md](HEALTHCHECK_README.md) - Health check system

### Operational Documentation
- [RAILWAY_DEPLOYMENT.md](RAILWAY_DEPLOYMENT.md) - Railway deployment guide
- [QUICK_REFERENCE.md](QUICK_REFERENCE.md) - Common commands reference
- [DASHBOARD_IMPROVEMENTS.md](DASHBOARD_IMPROVEMENTS.md) - Dashboard feature history

### Status Documentation
- [SIMPLIFIED_DASHBOARD.md](SIMPLIFIED_DASHBOARD.md) - Recent dashboard changes
- [ANONYMOUS_ROW_FILTERING.md](ANONYMOUS_ROW_FILTERING.md) - Row filtering implementation
- [EMPTY_ROW_VALIDATION.md](EMPTY_ROW_VALIDATION.md) - Validation logic
- [LOCAL_SITE_RUNNING.md](LOCAL_SITE_RUNNING.md) - Local development status

---

## ğŸ“ Learning Resources

### Flask Documentation
- https://flask.palletsprojects.com/
- Template rendering, routing, sessions

### SQLAlchemy
- https://www.sqlalchemy.org/
- ORM patterns, migrations

### Google Sheets API
- https://developers.google.com/sheets/api
- Authentication, data extraction

### Railway Platform
- https://railway.app/docs
- Deployment, environment variables, databases

---

## ğŸ†˜ Getting Help

### Health Check First
```bash
python healthcheck.py
```

### Check Logs
```bash
# Local
tail -f app.log

# Railway
railway logs --tail
```

### Common Issues
See [Troubleshooting](#-troubleshooting) section above

### Additional Resources
1. Check relevant documentation in [Additional Documentation](#-additional-documentation)
2. Review [Recent Updates](#recent-updates) for latest changes
3. Examine git commit history for context
4. Run health checks for system status

---

## ğŸ“ Support

**For issues or questions:**
1. Check [Troubleshooting](#-troubleshooting) section
2. Review [Additional Documentation](#-additional-documentation)
3. Run health checks: `python healthcheck.py`
4. Check application logs for detailed error messages
5. Review recent git commits for related changes

---

**Built with Python, Flask, SQLite/PostgreSQL, and Tailwind CSS**
**Optimized for Claude Code and agentic coders**

---

## ğŸ“ˆ Recent Activity Summary (Last 30 Days)

### Development Statistics
- **82 commits** by Robert (Masa) Matsuoka
- **Primary focus:** PostgreSQL migration and production stability
- **Most modified file:** app.py (56 changes)
- **Active branch:** master (stable)

### Key Development Areas

#### Database Migration (Oct 6-7)
- Fixed PostgreSQL schema compatibility for survey normalization
- Improved INSERT OR REPLACE conversion for sync_tracking table
- Ensured sync_tracking table creation on PostgreSQL startup
- Migrated from SQLite to PostgreSQL with full schema parity

#### Architecture Improvements (Oct 6)
- Implemented single source of truth architecture with auto-regenerating PostgreSQL
- Added API endpoints for SQLite to PostgreSQL migration
- Updated schema to match SQLite normalized structure exactly
- Created database verification and recreation endpoints

#### Documentation Enhancements (Oct 6)
- Added comprehensive development guides and deployment documentation
- Created security debt documentation for v1.0.1
- Enhanced Makefile with comprehensive command system
- Removed obsolete deployment documentation

#### User Experience (Oct 6)
- Standardized UI terminology from 'response' to 'submission'
- Fixed cache headers and PostgreSQL route detection
- Improved survey data verification endpoints

### Technical Debt Addressed
- âœ… PostgreSQL boolean casting and foreign key handling
- âœ… SQLite datetime() to PostgreSQL conditional query conversion
- âœ… RealDictCursor dictionary access compatibility
- âœ… Schema synchronization between local and production environments

### Files with Significant Updates
1. **app.py** - Core application logic (56 modifications)
2. **templates/dashboard.html** - UI improvements (6 modifications)
3. **survey_analytics.py** - Analytics engine updates (5 modifications)
4. **railway_init.py** - Production initialization (4 modifications)
5. **survey_normalizer.py** - Schema compatibility fixes (3 modifications)

### Next Focus Areas
- Continue monitoring PostgreSQL production stability
- Enhance health check coverage for database migrations
- Improve error handling for edge cases
- Expand test coverage for PostgreSQL-specific logic

---

*Last updated: 2025-10-09*
*CLAUDE.md Version: 1.0.0*
